---
title: "Learning machine learning"
publishedAt: "2024-11-29"
summary: ""
---

I learned to code when I was 7 or 8 (that'd be the year 2000) and more or less
kept tinkering until I went to college in 2010. That era looked like: perl, js,
php, and FTP for deployment. Ode to dreamweaver.

I then took an extended break until about 2019 when I got back into coding, and
started doing engineering for work. Nowadays that looks like (python+js+sql),
vscode and github, but for the first 3 months of re-learning coding for me
looked like python and google colab.

Google colab is actually a really underrated IDE outside of data science.

- Jupyter notebook without thinking about self-hosting? Check.
- Google-docs like realtime colaborative editing? Check.
- Corgie mode? Check!!

Anyway, whereas the kind of data engineering I did for the past four years was
a lot of serverless, columnar SQL databases, organized into bits in DBT, and
python for orchestration, those first couple of months of re-learning for me
looked more like toying with python, numpy, pandas, matplotlib, and
scikit-learn, and learning some simple practice regression modeling and
randomly tacking on xgboost to things.

In essence though, I was mostly re-teaching myself coding in general. The
underlying principles of the data science-y parts of the python ecyosystem were
greek to me -- my college math never went past diff eq, and I tapped out before
linear algebra and real statistics.

So as I come back to an interest in cognitive science, I'm interested in diving
into machine learning and figured I'd started writing down my learning path.

My starting point is sort of carving what I think I might even be learning into
different buckets:

- Current application domains of generative AI
- MLops
- Applied data engineering for ML
- Deep learning
- Basic mathematical foundations of deep learning (linear algebra,
  statistics)
- Enlarging my knowlege of statistics perpendicularly away from deep
  learning's current sota

This is dividing it up sort of chronologically in the same order as I've begun
to understand the generics. Here's some of my starting places for learning
about what I even need to learn:

- Andrej Karpathy's [Neural Networks course](https://karpathy.ai/zero-to-hero.html)
- Ian Goodfellow's textbook [Deep Learning](https://www.amazon.com/Deep-Learning-Adaptive-Computation-Machine/dp/0262035618/ref=sr_1_1?ie=UTF8&qid=1472485235&sr=8-1&keywords=deep+learning+book)
- Luis Serrano's [Mathematics for Machine Learning and Data Science](https://www.coursera.org/specializations/mathematics-for-machine-learning-and-data-science)
- [Designing Machine Learning Systems: An Iterative Process for Production-Ready Applications](https://www.amazon.com/dp/1098107969?ref=ppx_yo2ov_dt_b_fed_asin_title)
- [Deep Learning for Coders with PyTorch](https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527/ref=tmm_pap_swatch_0?_encoding=UTF8&dib_tag=se&dib=eyJ2IjoiMSJ9.FoiyUrT1HrrDZWcmrtxRSdaAy-r4QQK6LtOUfn18vt2Lf8tKMgknBHiqOhzRK4yjzdRsy6GzGWQO2HNzeTppxX0ubUNFrMwwhwDtRGjOrUYjUMkRjDfgYZGyS5DeMNdGGXSByUVM0AHawN3aMgqCd7hzx0NE9KcyQqkwNw2-v3qpIZrl0abKZO7DAWkov32RECDpMbLXNwV4-lNL1B1zSnXwukX06KfKm9DeUdmbLJpXVou_9IHBXVWXlsZDRIP2VC4NUh2Vn_GbXp34IsLAn4BlE7HchOlUTRoIsYZSxAM.3X69k0F1-xlEAR08xnlmCbDwhX1furgePX6Ab5jRJ1k&qid=1732929877&sr=1-3)

I'm planning to write more as I go finish these resources.
